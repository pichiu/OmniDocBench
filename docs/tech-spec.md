# OmniDocBench - Technical Specification

**Author:** BMad
**Date:** 2025-11-13
**Project Level:** 0
**Change Type:** New Feature
**Development Context:** Brownfield

---

## Context

### Available Documents

**å·²æ‰¾åˆ°çš„æ–‡ä»¶:**

âœ… **å°ˆæ¡ˆæ–‡ä»¶åˆ†æ (document-project)**: å·²å®Œæˆ
- `docs/index.md` - å®Œæ•´çš„å°ˆæ¡ˆç´¢å¼•
- `docs/architecture.md` - æ¶æ§‹æ–‡æª”
- `docs/development-guide.md` - é–‹ç™¼æŒ‡å—
- `docs/project-overview.md` - å°ˆæ¡ˆæ¦‚è¦½
- `docs/source-tree-analysis.md` - åŸå§‹ç¢¼æ¨¹ç‹€çµæ§‹

âŒ **ç”¢å“ç°¡å ± (Product Brief)**: æœªæ‰¾åˆ°
âŒ **ç ”ç©¶æ–‡ä»¶ (Research)**: æœªæ‰¾åˆ°

**æ–‡ä»¶å“è³ª**: æŠ€è¡“æ–‡æª”éå¸¸å®Œæ•´ï¼Œæ¶µè“‹æ¶æ§‹ã€é–‹ç™¼æŒ‡å—ã€API è¨­è¨ˆç­‰å„æ–¹é¢ã€‚

### Project Stack

**å°ˆæ¡ˆåç¨±**: OmniDocBench
**å°ˆæ¡ˆé¡å‹**: æ•¸æ“šè™•ç†èˆ‡è©•ä¼°ç®¡é“ (Monolith æ¶æ§‹)
**ç‰ˆæœ¬**: v1.5
**ä¸»è¦èªè¨€**: Python 3.x (æ¨è–¦ 3.8+)

**æ ¸å¿ƒæ¡†æ¶èˆ‡ä¾è³´ç‰ˆæœ¬**:

**æ•¸æ“šè™•ç†å±¤**:
- pandas 2.0.3 - æ•¸æ“šåˆ†æå’Œè™•ç†
- numpy 1.24.4 - æ•¸å€¼è¨ˆç®—åŸºç¤
- datasets 3.1.0 - HuggingFace æ•¸æ“šé›†æ”¯æŒ
- pyarrow 17.0.0 - é«˜æ•ˆæ•¸æ“šåºåˆ—åŒ–

**è¨ˆç®—æ©Ÿè¦–è¦ºå±¤**:
- opencv-python 4.10.0.84 - åœ–åƒè™•ç†
- Pillow 10.4.0 - åœ–åƒæ“ä½œ
- matplotlib 3.7.5 - å¯è¦–åŒ–

**è©•ä¼°æŒ‡æ¨™å±¤**:
- mmeval 0.2.1 - å¤šæ¨¡æ…‹è©•ä¼°æ¡†æ¶
- evaluate 0.4.3 - HuggingFace è©•ä¼°å·¥å…·
- scikit-learn 1.1.2 - æ©Ÿå™¨å­¸ç¿’æŒ‡æ¨™
- pycocotools 2.0.7 - COCO æ ¼å¼æª¢æ¸¬è©•ä¼°

**æ–‡æœ¬è™•ç†å±¤**:
- nltk 3.9.1 - è‡ªç„¶èªè¨€è™•ç†
- Levenshtein 0.25.1 - ç·¨è¼¯è·é›¢è¨ˆç®—
- rapidfuzz 3.9.7 - å¿«é€Ÿæ¨¡ç³ŠåŒ¹é…
- pylatexenc 3.0a30 - LaTeX ç·¨ç¢¼è™•ç†

**é…ç½®å’Œå·¥å…·å±¤**:
- PyYAML 6.0.2 - YAML è§£æ
- click 8.1.7 - CLI æ§‹å»º
- loguru 0.7.2 - æ—¥èªŒè¨˜éŒ„
- tqdm 4.67.1 - é€²åº¦æ¢

**API èª¿ç”¨å±¤**:
- openai - OpenAI SDK (éœ€ç¢ºèªæ˜¯å¦å·²å®‰è£)

**æ¸¬è©¦æ¡†æ¶**: åŸºæ–¼ demo_data é€²è¡Œé©—è­‰æ¸¬è©¦ï¼ˆç„¡æ­£å¼å–®å…ƒæ¸¬è©¦æ¡†æ¶ï¼‰

### Existing Codebase Structure

**å°ˆæ¡ˆé¡å‹**: Brownfield - ç¾æœ‰æˆç†Ÿçš„ç¨‹å¼ç¢¼åº«

**æ¶æ§‹æ¨¡å¼**:
- ğŸ“¦ **è¨»å†Šè¡¨æ¨¡å¼ (Registry Pattern)** - å‹•æ…‹çµ„ä»¶ç®¡ç†
- ğŸ”„ **ç®¡é“æ¶æ§‹ (Pipeline Architecture)** - ç·šæ€§è©•ä¼°æµç¨‹
- ğŸ§© **æ¨¡å¡ŠåŒ–è¨­è¨ˆ** - æ¸…æ™°çš„å±¤æ¬¡åˆ†é›¢

**ç›®éŒ„çµæ§‹**:
```
OmniDocBench/
â”œâ”€â”€ configs/          # YAML é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ DeepSeek-OCR-vllm/  # DeepSeek-OCR æœ¬åœ°é…ç½®
â”œâ”€â”€ task/             # è©•ä¼°ä»»å‹™å¯¦ç¾
â”œâ”€â”€ dataset/          # æ•¸æ“šé›†åŠ è¼‰å™¨
â”œâ”€â”€ metrics/          # è©•ä¼°æŒ‡æ¨™
â”œâ”€â”€ utils/            # å·¥å…·å‡½æ•¸å’ŒåŒ¹é…ç®—æ³•
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ model_infer/  # æ¨¡å‹æ¨ç†è…³æœ¬ â­ (æˆ‘å€‘çš„ç›®æ¨™ä½ç½®)
â”œâ”€â”€ registry/         # è¨»å†Šè¡¨ç³»çµ±
â”œâ”€â”€ demo_data/        # æ¼”ç¤ºæ•¸æ“š
â””â”€â”€ result/           # è©•ä¼°çµæœè¼¸å‡º
```

**é—œéµè¨­è¨ˆæ¨¡å¼**:
1. **è£é£¾å™¨è¨»å†Š** - ä½¿ç”¨ `@REGISTRY.register()` è¨»å†Šçµ„ä»¶
2. **YAML é…ç½®é©…å‹•** - æ‰€æœ‰è©•ä¼°é€šé YAML æ–‡ä»¶é…ç½®
3. **çµ±ä¸€ API æ¥å£** - æ‰€æœ‰æŒ‡æ¨™éµå¾ªç›¸åŒçš„ `evaluate()` æ¥å£
4. **GT-Pred åŒ¹é…ç®—æ³•** - quick_match, full_match ç­‰åŒ¹é…ç­–ç•¥

**ç¾æœ‰æ¨ç†è…³æœ¬**:
- `tools/model_infer/gpt_4o_inf.py` - GPT-4o é€šé OpenAI API èª¿ç”¨
- `configs/run_dpsk_ocr_eval_batch.py` - DeepSeek-OCR æœ¬åœ° vllm æ‰¹è™•ç†

---

## The Change

### Problem Statement

ç›®å‰ OmniDocBench å·²æ”¯æŒé€šé OpenAI API èª¿ç”¨ GPT-4o é€²è¡Œæ–‡æª”è§£æè©•ä¼°ï¼ˆ`gpt_4o_inf.py`ï¼‰ï¼Œä¹Ÿæ”¯æŒæœ¬åœ° vllm æ‰¹è™•ç† DeepSeek-OCRï¼ˆ`run_dpsk_ocr_eval_batch.py`ï¼‰ã€‚

ä½†ç¼ºå°‘ **é€šé OpenAI Compatible API èª¿ç”¨é ç¨‹ vllm DeepSeek-OCR æœå‹™** çš„æ–¹å¼ã€‚é€™å°è‡´ï¼š

1. ç„¡æ³•åˆ©ç”¨å·²æ¶è¨­çš„é ç¨‹ vllm æœå‹™
2. å¿…é ˆåœ¨æœ¬åœ°ç’°å¢ƒå®‰è£å®Œæ•´çš„ vllm + torch + transformers ä¾è³´
3. ç„¡æ³•ä½¿ç”¨è¼•é‡ç´šå®¢æˆ¶ç«¯é€²è¡Œæ‰¹é‡æ¨ç†

### Proposed Solution

æ–°å¢ `tools/model_infer/deepseek_ocr_inf.py` æ¨ç†è…³æœ¬ï¼Œé€šé OpenAI Compatible API èª¿ç”¨å·²æ¶è¨­çš„ vllm DeepSeek-OCR æœå‹™ã€‚

**æ ¸å¿ƒç‰¹æ€§**:
1. âœ… ä½¿ç”¨ OpenAI SDK èª¿ç”¨ vllm APIï¼ˆbase64 åœ–åƒå‚³è¼¸ï¼‰
2. âœ… é›†æˆ DeepSeek-OCR å°ˆç”¨å¾Œè™•ç†é‚è¼¯
3. âœ… ç”Ÿæˆé›™è¼¸å‡ºï¼šåŸå§‹ + æ¸…ç†å¾Œçš„ Markdown
4. âœ… æ”¯æŒå¤šç·šç¨‹ä¸¦è¡Œè™•ç†
5. âœ… å®Œå…¨åƒæ•¸åŒ–é…ç½®ï¼ˆAPI endpoint, model name, threadsï¼‰

**æŠ€è¡“å„ªå‹¢**:
- å®¢æˆ¶ç«¯è¼•é‡åŒ–ï¼ˆä¸éœ€è¦ torch/transformersï¼‰
- åœ–åƒé è™•ç†ç”± vllm æœå‹™ç«¯è™•ç†ï¼ˆå·²é…ç½® DeepseekOCRProcessorï¼‰
- èˆ‡ç¾æœ‰ `gpt_4o_inf.py` æ¶æ§‹ä¸€è‡´ï¼Œæ˜“æ–¼ç¶­è­·

### Scope

**In Scope:**

âœ… æ–°å»º `tools/model_infer/deepseek_ocr_inf.py`
âœ… ä½¿ç”¨ OpenAI Compatible API èª¿ç”¨ vllm
âœ… Base64 åœ–åƒç·¨ç¢¼å’Œå‚³è¼¸
âœ… DeepSeek-OCR å°ˆç”¨ prompt: `'Convert the document to markdown.'`
âœ… ç”Ÿæˆé›™è¼¸å‡º:
  - `{basename}_det.md` - åŸå§‹ API è¼¸å‡ºï¼ˆå«ç‰¹æ®Šæ¨™è¨˜ï¼‰
  - `{basename}.md` - æ¸…ç†å¾Œè¼¸å‡ºï¼ˆç§»é™¤æ¨™è¨˜ã€æ¸…ç†å…¬å¼ï¼‰
âœ… é›†æˆå¾Œè™•ç†å‡½æ•¸:
  - `clean_formula()` - æ¸…ç†å…¬å¼ä¸­çš„ `\quad(...)` æ¨™è¨˜
  - `re_match()` - æå–ä¸¦ç§»é™¤ `<|ref|>...<|det|>` æ¨™è¨˜
âœ… å¤šç·šç¨‹ä¸¦è¡Œè™•ç† + é€²åº¦æ¢
âœ… å‘½ä»¤è¡Œåƒæ•¸é…ç½®
âœ… éŒ¯èª¤è™•ç†å’Œæ—¥èªŒ

**Out of Scope:**

âŒ ä¸ä¿®æ”¹ç¾æœ‰çš„ `gpt_4o_inf.py`
âŒ ä¸ä¿®æ”¹ç¾æœ‰çš„ `run_dpsk_ocr_eval_batch.py`
âŒ ä¸åŒ…å«å®¢æˆ¶ç«¯åœ–åƒé è™•ç†é‚è¼¯ï¼ˆç”± vllm æœå‹™ç«¯è™•ç†ï¼‰
âŒ ä¸åŒ…å« vllm æœå‹™é…ç½®æˆ–éƒ¨ç½²èªªæ˜
âŒ ä¸æ·»åŠ æ–°çš„è©•ä¼°æŒ‡æ¨™æˆ–ä»»å‹™
âŒ ä¸ä¿®æ”¹è¨»å†Šè¡¨ç³»çµ±æˆ–æ ¸å¿ƒæ¶æ§‹

---

## Implementation Details

### Source Tree Changes

**æ–°å»ºæ–‡ä»¶**:
```
tools/model_infer/
â”œâ”€â”€ gpt_4o_inf.py              # ç¾æœ‰ï¼ˆåƒè€ƒæ¨¡æ¿ï¼‰
â”œâ”€â”€ deepseek_ocr_inf.py        # æ–°å»º â­
â””â”€â”€ ...å…¶ä»–æ¨ç†è…³æœ¬
```

**æ“ä½œ**: CREATE `tools/model_infer/deepseek_ocr_inf.py`

**æ–‡ä»¶ç”¨é€”**: é€šé OpenAI Compatible API æ‰¹é‡èª¿ç”¨ vllm DeepSeek-OCR æœå‹™ï¼Œç”Ÿæˆæ–‡æª” Markdown è¼¸å‡º

### Technical Approach

**è¨­è¨ˆæ±ºç­– - ç‚ºä»€éº¼é¸æ“‡ OpenAI Compatible API?**

1. **æœå‹™ç«¯è™•ç†åœ–åƒé è™•ç†** âœ…
   - vllm æœå‹™å·²é…ç½® `DeepseekOCRProcessor`
   - è‡ªå‹•è™•ç†å‹•æ…‹è£å‰ªã€paddingã€normalization
   - å®¢æˆ¶ç«¯åªéœ€ç™¼é€åŸå§‹ base64 åœ–åƒ

2. **è¼•é‡ç´šå®¢æˆ¶ç«¯** âœ…
   - ä¸éœ€è¦å®‰è£ torch (1.5GB+), transformers, vllm
   - åªéœ€ openai SDK + åŸºç¤ä¾è³´
   - é©åˆåœ¨ä»»ä½•ç’°å¢ƒé‹è¡Œ

3. **æ¨™æº–åŒ–æ¥å£** âœ…
   - éµå¾ª OpenAI API æ¨™æº–
   - èˆ‡ `gpt_4o_inf.py` æ¶æ§‹ä¸€è‡´
   - æ˜“æ–¼ç¶­è­·å’Œæ“´å±•

**æ ¸å¿ƒæ¶æ§‹**:

```python
# ä¸»è¦çµ„ä»¶
main()                      # å‘½ä»¤è¡Œ + å¤šç·šç¨‹å”èª¿
â”œâ”€â”€ process_image()         # å–®åœ–åƒè™•ç†ï¼ˆThreadPool èª¿ç”¨ï¼‰
    â”œâ”€â”€ get_deepseek_response()  # API èª¿ç”¨
    â”‚   â””â”€â”€ OpenAI SDK -> vllm API
    â”œâ”€â”€ ä¿å­˜åŸå§‹è¼¸å‡º (_det.md)
    â””â”€â”€ å¾Œè™•ç†ä¸¦ä¿å­˜ (.md)
        â”œâ”€â”€ clean_formula()      # å…¬å¼æ¸…ç†
        â””â”€â”€ re_match() + ç§»é™¤æ¨™è¨˜  # ç‰¹æ®Šæ¨™è¨˜è™•ç†
```

**API èª¿ç”¨æµç¨‹**:

```python
# 1. åœ–åƒç·¨ç¢¼
with open(image_path, "rb") as f:
    image_bytes = f.read()
img_str = base64.b64encode(image_bytes).decode()

# 2. èª¿ç”¨ OpenAI Compatible API
client = OpenAI(api_key=api_key, base_url=base_url)
completion = client.chat.completions.create(
    model=model_name,
    messages=[{
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{img_str}"}
            },
            {"type": "text", "text": PROMPT}
        ]
    }],
    temperature=0.0
)

# 3. ç²å–éŸ¿æ‡‰
response = completion.choices[0].message.content
```

**å¾Œè™•ç†é‚è¼¯** (å¾ `run_dpsk_ocr_eval_batch.py` ç§»æ¤):

```python
# 1. æ¸…ç†å…¬å¼
def clean_formula(text):
    """ç§»é™¤å…¬å¼ä¸­çš„ \\quad(...) æ¨™è¨˜"""
    formula_pattern = r'\\\[(.*?)\\\]'

    def process_formula(match):
        formula = match.group(1)
        formula = re.sub(r'\\quad\s*\([^)]*\)', '', formula)
        return r'\[' + formula.strip() + r'\]'

    return re.sub(formula_pattern, process_formula, text)

# 2. æå–ä¸¦ç§»é™¤ç‰¹æ®Šæ¨™è¨˜
def re_match(text):
    """æå– <|ref|>...<|det|> æ¨™è¨˜"""
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)
    matches_other = [match[0] for match in matches]
    return matches, matches_other

# 3. æ¸…ç†æ›è¡Œ
cleaned = text.replace('\n\n\n\n', '\n\n').replace('\n\n\n', '\n\n')
cleaned = cleaned.replace('<center>', '').replace('</center>', '')
```

**Prompt ä½¿ç”¨**:

```python
PROMPT = 'Convert the document to markdown.'
```

ç°¡åŒ–çš„ prompt é©ç”¨æ–¼ OpenAI Compatible API èª¿ç”¨ï¼š
- åœ–åƒé€šé API `messages` çµæ§‹çš„ `image_url` å‚³éï¼Œä¸éœ€è¦ `<image>` æ¨™è¨˜
- `<|grounding|>` æ˜¯ DeepSeek-OCR æœ¬åœ°èª¿ç”¨æ™‚çš„æ¨¡å¼æ¨™è¨˜ï¼ŒOpenAI API å¯èƒ½è‡ªå‹•è™•ç†æˆ–ä¸éœ€è¦
- ä¿æŒ prompt ç°¡æ½”æ¸…æ™°

### Existing Patterns to Follow

**å¾ `gpt_4o_inf.py` éµå¾ªçš„æ¨¡å¼**:

1. **OpenAI SDK ä½¿ç”¨**:
```python
from openai import OpenAI
client = OpenAI(api_key=..., base_url=...)
```

2. **Base64 åœ–åƒç·¨ç¢¼**:
```python
with open(image_path, "rb") as f:
    image_bytes = f.read()
img_str = base64.b64encode(image_bytes).decode()
```

3. **å¤šç·šç¨‹ä¸¦è¡Œè™•ç†**:
```python
with ThreadPoolExecutor(max_workers=num_threads) as executor:
    results = list(tqdm(
        executor.map(process_image, image_files),
        total=len(image_files),
        desc="è™•ç†é€²åº¦"
    ))
```

4. **éŒ¯èª¤è™•ç†**:
```python
try:
    response = get_gpt_response(image_path)
except Exception as e:
    print(f"[ERROR] Failed to get response: {e}")
    return ""
```

5. **å‘½ä»¤è¡Œåƒæ•¸**:
```python
parser.add_argument("--image_root", type=str, help="åœ–åƒæ–‡ä»¶å¤¾è·¯å¾‘")
parser.add_argument("--save_root", type=str, help="ä¿å­˜çµæœçš„æ–‡ä»¶å¤¾è·¯å¾‘")
parser.add_argument("--threads", type=int, default=10, help="ä¸¦è¡Œç·šç¨‹æ•¸")
```

**å¾ `run_dpsk_ocr_eval_batch.py` éµå¾ªçš„æ¨¡å¼**:

1. **é›™è¼¸å‡ºç”Ÿæˆ**:
```python
# åŸå§‹è¼¸å‡º
mmd_det_path = output_path + image_name.replace('.jpg', '_det.md')
with open(mmd_det_path, 'w', encoding='utf-8') as f:
    f.write(raw_content)

# æ¸…ç†å¾Œè¼¸å‡º
mmd_path = output_path + image_name.replace('.jpg', '.md')
with open(mmd_path, 'w', encoding='utf-8') as f:
    f.write(cleaned_content)
```

2. **å¾Œè™•ç†å‡½æ•¸**: `clean_formula()`, `re_match()` å®Œå…¨ç§»æ¤

3. **é€²åº¦æ¢å’Œæ—¥èªŒ**: ä½¿ç”¨ tqdm é¡¯ç¤ºè™•ç†é€²åº¦

### Integration Points

**å¤–éƒ¨ä¾è³´**:
- **vllm API æœå‹™** - å¿…é ˆå·²æ¶è¨­ä¸¦é…ç½® DeepSeek-OCR
  - éœ€è¦æ”¯æŒ OpenAI Compatible API (`/v1/chat/completions`)
  - éœ€è¦é…ç½® `trust_remote_code=True`
  - éœ€è¦é…ç½® `DeepseekOCRProcessor` é€²è¡Œåœ–åƒé è™•ç†

**è¼¸å…¥**:
- åœ–åƒæ–‡ä»¶å¤¾ï¼ˆæ”¯æ´ `.jpg`, `.png`, `.jpeg`ï¼‰
- API é…ç½®ï¼ˆbase_url, api_key, model_nameï¼‰

**è¼¸å‡º**:
- `{basename}_det.md` - åŸå§‹ API è¼¸å‡º
- `{basename}.md` - æ¸…ç†å¾Œçš„ Markdown

**ä¸èˆ‡å…¶ä»–æ¨¡å¡Šäº¤äº’**:
- é€™æ˜¯ç¨ç«‹çš„æ¨ç†è…³æœ¬
- ä¸èª¿ç”¨è¨»å†Šè¡¨ç³»çµ±
- ä¸èª¿ç”¨è©•ä¼°ä»»å‹™æˆ–æŒ‡æ¨™
- åªè² è²¬: åœ–åƒ â†’ API â†’ Markdown æ–‡ä»¶

---

## Development Context

### Relevant Existing Code

**åƒè€ƒæ–‡ä»¶ 1**: `tools/model_infer/gpt_4o_inf.py`
- ä½ç½®: tools/model_infer/gpt_4o_inf.py:1-113
- ç”¨é€”: OpenAI API èª¿ç”¨æ¶æ§‹åƒè€ƒ
- é—œéµå‡½æ•¸:
  - `get_gpt_response()` - API èª¿ç”¨æ¨¡æ¿
  - `process_image()` - å–®åœ–è™•ç†æ¨¡æ¿
  - `main()` - å¤šç·šç¨‹å”èª¿æ¨¡æ¿

**åƒè€ƒæ–‡ä»¶ 2**: `configs/run_dpsk_ocr_eval_batch.py`
- ä½ç½®: configs/run_dpsk_ocr_eval_batch.py:53-162
- ç”¨é€”: DeepSeek-OCR å¾Œè™•ç†é‚è¼¯åƒè€ƒ
- é—œéµå‡½æ•¸:
  - `clean_formula()` (L53-68) - å…¬å¼æ¸…ç†
  - `re_match()` (L70-79) - ç‰¹æ®Šæ¨™è¨˜æå–
  - é›™è¼¸å‡ºé‚è¼¯ (L145-161)

**åƒè€ƒæ–‡ä»¶ 3**: `configs/DeepSeek-OCR-vllm/config.py`
- ä½ç½®: configs/DeepSeek-OCR-vllm/config.py:27
- ç”¨é€”: DeepSeek-OCR å®˜æ–¹ prompt åƒè€ƒ
- æ³¨æ„: æœ¬åœ°èª¿ç”¨ä½¿ç”¨ `'<image>\n<|grounding|>Convert the document to markdown.'`ï¼Œä½† OpenAI API èª¿ç”¨ç°¡åŒ–ç‚º `'Convert the document to markdown.'`

### Dependencies

**Framework/Libraries:**

ç¾æœ‰ä¾è³´ï¼ˆå·²åœ¨ requirements.txtï¼‰:
- Pillow 10.4.0 - åœ–åƒè®€å–
- tqdm 4.67.1 - é€²åº¦æ¢
- Python 3.7+ - åŸºç¤é‹è¡Œç’°å¢ƒ

éœ€è¦ç¢ºèªçš„ä¾è³´:
- **openai** - OpenAI SDKï¼ˆéœ€ç¢ºèªæ˜¯å¦å·²å®‰è£ï¼Œå¯èƒ½éœ€è¦æ·»åŠ åˆ° requirements.txtï¼‰

ä¸éœ€è¦çš„ä¾è³´ï¼ˆvllm æœå‹™ç«¯è™•ç†ï¼‰:
- torch - vllm æœå‹™ç«¯ä½¿ç”¨
- transformers - vllm æœå‹™ç«¯ä½¿ç”¨
- vllm - vllm æœå‹™ç«¯ä½¿ç”¨
- DeepseekOCRProcessor - vllm æœå‹™ç«¯ä½¿ç”¨

**Internal Modules:**

ç„¡å…§éƒ¨æ¨¡å¡Šä¾è³´ - é€™æ˜¯ç¨ç«‹çš„æ¨ç†è…³æœ¬

### Configuration Changes

**å¯èƒ½éœ€è¦æ›´æ–°** `requirements.txt`:

```txt
# æª¢æŸ¥æ˜¯å¦å·²åŒ…å« openai
openai>=1.0.0  # éœ€è¦æ”¯æŒ chat.completions API
```

**ç„¡éœ€ä¿®æ”¹å…¶ä»–é…ç½®æ–‡ä»¶**:
- ä¸ä¿®æ”¹ YAML è©•ä¼°é…ç½®
- ä¸ä¿®æ”¹è¨»å†Šè¡¨
- ä¸ä¿®æ”¹ç¾æœ‰è…³æœ¬

### Existing Conventions (Brownfield)

**ä»£ç¢¼é¢¨æ ¼**:
- **èªè¨€**: Python 3.x
- **ç¸®é€²**: 4 ç©ºæ ¼
- **å¼•è™Ÿ**: é›™å¼•è™Ÿç‚ºä¸»
- **å‘½å**:
  - å‡½æ•¸: snake_case (`get_deepseek_response`, `process_image`)
  - å¸¸é‡: UPPER_CASE (`PROMPT`, `API_KEY`)
  - è®Šé‡: snake_case

**æ–‡ä»¶çµ„ç¹”**:
- æ¨ç†è…³æœ¬æ”¾åœ¨ `tools/model_infer/`
- é…ç½®è…³æœ¬æ”¾åœ¨ `configs/`
- è¼¸å‡ºçµæœæ”¾åœ¨ç”¨æˆ¶æŒ‡å®šçš„ `save_root`

**éŒ¯èª¤è™•ç†**:
- ä½¿ç”¨ try-except æ•ç²ç•°å¸¸
- æ‰“å° `[ERROR]` å‰ç¶´çš„éŒ¯èª¤ä¿¡æ¯
- å¤±æ•—æ™‚è¿”å›ç©ºå­—ç¬¦ä¸²æˆ–è·³é

**æ—¥èªŒé¢¨æ ¼**:
- ä½¿ç”¨ `print()` è¼¸å‡ºæ—¥èªŒï¼ˆæ¨ç†è…³æœ¬ä¸ä½¿ç”¨ loguruï¼‰
- ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦
- é¡¯ç¤ºæˆåŠŸ/å¤±æ•—çµ±è¨ˆ

**å‘½ä»¤è¡Œåƒæ•¸é¢¨æ ¼**:
- ä½¿ç”¨ `argparse`
- æä¾› `--help` èªªæ˜
- ä½¿ç”¨é•·åƒæ•¸åï¼ˆ`--image_root` è€Œé `-i`ï¼‰

### Test Framework & Standards

**æ¸¬è©¦æ–¹æ³•**:
- **ç„¡æ­£å¼å–®å…ƒæ¸¬è©¦æ¡†æ¶**ï¼ˆé …ç›®ä½¿ç”¨ demo_data é©—è­‰ï¼‰
- æ¨ç†è…³æœ¬é€šéå¯¦éš›é‹è¡Œé©—è­‰

**é©—è­‰æ–¹å¼**:
1. **åŠŸèƒ½æ¸¬è©¦**: ä½¿ç”¨ `demo_data/omnidocbench_demo/images/` ä¸­çš„åœ–åƒæ¸¬è©¦
2. **è¼¸å‡ºé©—è­‰**: æª¢æŸ¥ç”Ÿæˆçš„ `_det.md` å’Œ `.md` æ–‡ä»¶
3. **å¾Œè™•ç†é©—è­‰**: ç¢ºèªç‰¹æ®Šæ¨™è¨˜è¢«æ­£ç¢ºç§»é™¤
4. **éŒ¯èª¤è™•ç†é©—è­‰**: æ¸¬è©¦ API å¤±æ•—ã€åœ–åƒè®€å–å¤±æ•—ç­‰å ´æ™¯

**é©—è­‰æ¸…å–®**:
- âœ… API èª¿ç”¨æˆåŠŸ
- âœ… ç”Ÿæˆ `_det.md`ï¼ˆåŸå§‹è¼¸å‡ºï¼‰
- âœ… ç”Ÿæˆ `.md`ï¼ˆæ¸…ç†å¾Œè¼¸å‡ºï¼‰
- âœ… å…¬å¼æ¸…ç†æ­£ç¢ºï¼ˆ`\quad(...)` è¢«ç§»é™¤ï¼‰
- âœ… ç‰¹æ®Šæ¨™è¨˜è¢«ç§»é™¤ï¼ˆ`<|ref|>`, `<|det|>` ç­‰ï¼‰
- âœ… å¤šç·šç¨‹ä¸¦è¡Œå·¥ä½œ
- âœ… é€²åº¦æ¢æ­£å¸¸é¡¯ç¤º
- âœ… éŒ¯èª¤å„ªé›…è™•ç†

---

## Implementation Stack

**é‹è¡Œç’°å¢ƒ**: Python 3.8+

**æ ¸å¿ƒä¾è³´**:
- openai >= 1.0.0 - OpenAI SDK
- Pillow 10.4.0 - åœ–åƒè®€å–
- tqdm 4.67.1 - é€²åº¦æ¢
- Python æ¨™æº–åº«:
  - argparse - å‘½ä»¤è¡Œåƒæ•¸
  - base64 - åœ–åƒç·¨ç¢¼
  - os - æ–‡ä»¶æ“ä½œ
  - re - æ­£å‰‡è¡¨é”å¼
  - concurrent.futures - å¤šç·šç¨‹

**é–‹ç™¼å·¥å…·**:
- Git - ç‰ˆæœ¬æ§åˆ¶
- Python venv - è™›æ“¬ç’°å¢ƒ

**å¤–éƒ¨æœå‹™**:
- vllm API æœå‹™ - å·²æ¶è¨­çš„ DeepSeek-OCR æœå‹™
  - æ”¯æŒ OpenAI Compatible API
  - é…ç½® DeepseekOCRProcessor

---

## Technical Details

### æ ¸å¿ƒç®—æ³•å’Œé‚è¼¯

**1. åœ–åƒç·¨ç¢¼**:
```python
def encode_image_to_base64(image_path: str) -> str:
    """è®€å–åœ–åƒä¸¦ç·¨ç¢¼ç‚º base64 å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as f:
        image_bytes = f.read()
    return base64.b64encode(image_bytes).decode()
```

**2. API èª¿ç”¨é‚è¼¯**:
```python
def get_deepseek_response(
    image_path: str,
    client: OpenAI,
    model_name: str
) -> str:
    """èª¿ç”¨ vllm API ç²å–éŸ¿æ‡‰"""
    # 1. ç·¨ç¢¼åœ–åƒ
    img_str = encode_image_to_base64(image_path)

    # 2. æ§‹å»ºè«‹æ±‚
    try:
        completion = client.chat.completions.create(
            model=model_name,
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{img_str}"
                        }
                    },
                    {"type": "text", "text": PROMPT}
                ]
            }],
            temperature=0.0
        )
        return completion.choices[0].message.content
    except Exception as e:
        print(f"[ERROR] Failed to get response: {e}")
        return ""
```

**3. å…¬å¼æ¸…ç†é‚è¼¯**:
```python
def clean_formula(text: str) -> str:
    """æ¸…ç†å…¬å¼ä¸­çš„ \\quad(...) æ¨™è¨˜

    ç¤ºä¾‹:
    è¼¸å…¥: \\[ E = mc^2 \\quad(equation 1) \\]
    è¼¸å‡º: \\[ E = mc^2 \\]
    """
    formula_pattern = r'\\\[(.*?)\\\]'

    def process_formula(match):
        formula = match.group(1)
        # ç§»é™¤ \quad(...) æ¨¡å¼
        formula = re.sub(r'\\quad\s*\([^)]*\)', '', formula)
        formula = formula.strip()
        return r'\[' + formula + r'\]'

    return re.sub(formula_pattern, process_formula, text)
```

**4. ç‰¹æ®Šæ¨™è¨˜è™•ç†**:
```python
def re_match(text: str) -> tuple:
    """æå– <|ref|>...<|det|> æ¨™è¨˜

    è¿”å›:
        (matches, matches_other)
        matches: å®Œæ•´åŒ¹é…å°è±¡åˆ—è¡¨
        matches_other: éœ€è¦ç§»é™¤çš„æ¨™è¨˜å­—ç¬¦ä¸²åˆ—è¡¨
    """
    pattern = r'(<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>)'
    matches = re.findall(pattern, text, re.DOTALL)

    matches_other = []
    for a_match in matches:
        matches_other.append(a_match[0])

    return matches, matches_other
```

**5. å®Œæ•´è™•ç†æµç¨‹**:
```python
def process_image(args) -> str:
    """è™•ç†å–®å¼µåœ–åƒ"""
    image_path, save_root, client, model_name = args
    file_name = os.path.basename(image_path)
    base_name = file_name.rsplit('.', 1)[0]

    try:
        # 1. èª¿ç”¨ API
        response = get_deepseek_response(image_path, client, model_name)

        # 2. ä¿å­˜åŸå§‹è¼¸å‡º (_det.md)
        det_path = os.path.join(save_root, f"{base_name}_det.md")
        with open(det_path, "w", encoding="utf-8") as f:
            f.write(response)

        # 3. æ¸…ç†ä¸¦ä¿å­˜ (.md)
        cleaned = clean_formula(response)
        matches_ref, matches_other = re_match(cleaned)

        # ç§»é™¤ç‰¹æ®Šæ¨™è¨˜
        for match in matches_other:
            cleaned = cleaned.replace(match, '')

        # æ¸…ç†å¤šé¤˜æ›è¡Œ
        cleaned = cleaned.replace('\n\n\n\n', '\n\n')
        cleaned = cleaned.replace('\n\n\n', '\n\n')
        cleaned = cleaned.replace('<center>', '').replace('</center>', '')

        # ä¿å­˜æ¸…ç†å¾Œçš„è¼¸å‡º
        output_path = os.path.join(save_root, f"{base_name}.md")
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(cleaned)

        return f"æˆåŠŸè™•ç†: {file_name}"

    except Exception as e:
        return f"è™•ç†å¤±æ•— {file_name}: {str(e)}"
```

### æ€§èƒ½è€ƒæ…®

**å¤šç·šç¨‹ä¸¦è¡Œ**:
- é»˜èª 10 å€‹ç·šç¨‹ï¼ˆå¯é…ç½®ï¼‰
- I/O å¯†é›†å‹ä»»å‹™ï¼ˆAPI èª¿ç”¨ã€æ–‡ä»¶è®€å¯«ï¼‰é©åˆå¤šç·šç¨‹
- é¿å… GIL é™åˆ¶ï¼ˆå¤§éƒ¨åˆ†æ™‚é–“åœ¨ç­‰å¾… API éŸ¿æ‡‰ï¼‰

**å…§å­˜ä½¿ç”¨**:
- åœ–åƒç·¨ç¢¼ç‚º base64 æœƒå¢åŠ ç´„ 33% å¤§å°
- æ‰¹é‡è™•ç†æ™‚æ³¨æ„å…§å­˜ä½¿ç”¨
- ç·šç¨‹æ•¸éå¤šå¯èƒ½å°è‡´å…§å­˜å£“åŠ›

**API é™é€Ÿ**:
- vllm æœå‹™å¯èƒ½æœ‰ä¸¦ç™¼é™åˆ¶
- å»ºè­°æ ¹æ“šæœå‹™ç«¯é…ç½®èª¿æ•´ `--threads` åƒæ•¸
- éŒ¯èª¤è™•ç†åŒ…å«é‡è©¦é‚è¼¯ï¼ˆå¯é¸ï¼‰

### å®‰å…¨è€ƒæ…®

**API Key ä¿è­·**:
- API key é€šéå‘½ä»¤è¡Œåƒæ•¸å‚³å…¥
- ä¸ç¡¬ç·¨ç¢¼åœ¨ä»£ç¢¼ä¸­
- å»ºè­°ä½¿ç”¨ç’°å¢ƒè®Šé‡: `export VLLM_API_KEY=xxx`

**æ–‡ä»¶æ“ä½œå®‰å…¨**:
- æª¢æŸ¥è¼¸å‡ºç›®éŒ„å­˜åœ¨æ€§ï¼ˆ`os.makedirs(exist_ok=True)`ï¼‰
- ä½¿ç”¨ UTF-8 ç·¨ç¢¼é¿å…äº‚ç¢¼
- ç•°å¸¸è™•ç†é˜²æ­¢å–®å€‹æ–‡ä»¶å¤±æ•—å½±éŸ¿æ•´é«”

### Edge Cases

**è™•ç†çš„é‚Šç•Œæƒ…æ³**:

1. **åœ–åƒæ–‡ä»¶ä¸å­˜åœ¨**:
```python
try:
    with open(image_path, "rb") as f:
        ...
except FileNotFoundError:
    return f"åœ–åƒä¸å­˜åœ¨: {image_path}"
```

2. **API èª¿ç”¨å¤±æ•—**:
```python
except Exception as e:
    print(f"[ERROR] API èª¿ç”¨å¤±æ•—: {e}")
    return ""
```

3. **ç©ºéŸ¿æ‡‰**:
```python
if not response:
    print(f"[WARNING] ç©ºéŸ¿æ‡‰: {file_name}")
    return
```

4. **ç‰¹æ®Šå­—ç¬¦è™•ç†**:
- UTF-8 ç·¨ç¢¼è™•ç†ä¸­æ–‡ã€ç‰¹æ®Šç¬¦è™Ÿ
- æ­£å‰‡è¡¨é”å¼è™•ç† LaTeX ç‰¹æ®Šå­—ç¬¦

5. **æ–‡ä»¶åè™•ç†**:
```python
# æ”¯æŒå¤šç¨®åœ–åƒæ ¼å¼
if file.endswith((".jpg", ".png", ".jpeg")):
    ...
```

---

## Development Setup

### ç’°å¢ƒæº–å‚™

```bash
# 1. ç¢ºèª Python ç‰ˆæœ¬
python --version  # éœ€è¦ >= 3.8

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. ç¢ºèª openai å·²å®‰è£ï¼ˆå¦‚æœæ²’æœ‰å‰‡å®‰è£ï¼‰
pip show openai || pip install openai>=1.0.0

# 5. é©—è­‰å®‰è£
python -c "import openai, PIL, tqdm; print('ä¾è³´å·²å°±ç·’')"
```

### vllm æœå‹™é©—è­‰

```bash
# 1. æ¸¬è©¦ API é€£é€šæ€§
curl $VLLM_BASE_URL/v1/models \
  -H "Authorization: Bearer $VLLM_API_KEY"

# 2. æ¸¬è©¦ chat completions endpoint
curl $VLLM_BASE_URL/v1/chat/completions \
  -H "Authorization: Bearer $VLLM_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-ai/DeepSeek-OCR",
    "messages": [{"role": "user", "content": "test"}]
  }'
```

### æ¸¬è©¦æ•¸æ“šæº–å‚™

```bash
# ä½¿ç”¨é …ç›®è‡ªå¸¶çš„ demo æ•¸æ“š
ls demo_data/omnidocbench_demo/images/

# æˆ–æº–å‚™è‡ªå·±çš„æ¸¬è©¦åœ–åƒ
mkdir test_images
cp your_document.jpg test_images/
```

---

## Implementation Guide

### Setup Steps

é–‹å§‹å¯¦ä½œå‰çš„æª¢æŸ¥æ¸…å–®:

1. âœ… **ç’°å¢ƒé©—è­‰**:
   - [ ] Python >= 3.8 å·²å®‰è£
   - [ ] è™›æ“¬ç’°å¢ƒå·²å‰µå»ºä¸¦æ¿€æ´»
   - [ ] requirements.txt ä¾è³´å·²å®‰è£
   - [ ] openai SDK å·²å®‰è£

2. âœ… **vllm æœå‹™é©—è­‰**:
   - [ ] vllm API æœå‹™æ­£åœ¨é‹è¡Œ
   - [ ] API endpoint å¯è¨ªå•
   - [ ] API key æœ‰æ•ˆ
   - [ ] DeepSeek-OCR æ¨¡å‹å·²åŠ è¼‰

3. âœ… **é …ç›®æº–å‚™**:
   - [ ] Git å·¥ä½œç›®éŒ„ä¹¾æ·¨
   - [ ] å‰µå»ºåŠŸèƒ½åˆ†æ”¯ï¼ˆå¯é¸ï¼‰
   - [ ] é–±è®€åƒè€ƒæ–‡ä»¶ï¼ˆ`gpt_4o_inf.py`, `run_dpsk_ocr_eval_batch.py`ï¼‰

4. âœ… **æ¸¬è©¦æ•¸æ“šæº–å‚™**:
   - [ ] æº–å‚™æ¸¬è©¦åœ–åƒï¼ˆ5-10 å¼µï¼‰
   - [ ] å‰µå»ºè¼¸å‡ºç›®éŒ„

### Implementation Steps

**æ­¥é©Ÿ 1: å‰µå»ºæ–‡ä»¶éª¨æ¶**

å‰µå»º `tools/model_infer/deepseek_ocr_inf.py`ï¼ŒåŒ…å«:
- å°å…¥å¿…è¦çš„åº«
- å®šç¾© PROMPT å¸¸é‡
- æ·»åŠ  `if __name__ == "__main__":` å…¥å£

**æ­¥é©Ÿ 2: å¯¦ç¾å¾Œè™•ç†å‡½æ•¸**

å¾ `run_dpsk_ocr_eval_batch.py` ç§»æ¤:
- `clean_formula()` å‡½æ•¸
- `re_match()` å‡½æ•¸

**æ­¥é©Ÿ 3: å¯¦ç¾ API èª¿ç”¨å‡½æ•¸**

åƒè€ƒ `gpt_4o_inf.py` å¯¦ç¾:
- `get_deepseek_response()` - API èª¿ç”¨
  - åœ–åƒç·¨ç¢¼
  - OpenAI SDK èª¿ç”¨
  - éŒ¯èª¤è™•ç†

**æ­¥é©Ÿ 4: å¯¦ç¾å–®åœ–è™•ç†å‡½æ•¸**

å¯¦ç¾ `process_image()`:
- èª¿ç”¨ `get_deepseek_response()`
- ä¿å­˜åŸå§‹è¼¸å‡º `_det.md`
- æ‡‰ç”¨å¾Œè™•ç†
- ä¿å­˜æ¸…ç†å¾Œè¼¸å‡º `.md`
- è¿”å›è™•ç†ç‹€æ…‹

**æ­¥é©Ÿ 5: å¯¦ç¾ä¸»å‡½æ•¸**

å¯¦ç¾ `main()`:
- å‘½ä»¤è¡Œåƒæ•¸è§£æ
- åˆå§‹åŒ– OpenAI client
- æ”¶é›†åœ–åƒæ–‡ä»¶åˆ—è¡¨
- ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡Œè™•ç†
- é¡¯ç¤ºé€²åº¦æ¢
- çµ±è¨ˆä¸¦é¡¯ç¤ºçµæœ

**æ­¥é©Ÿ 6: æ¸¬è©¦å’Œèª¿è©¦**

- ä½¿ç”¨ 1 å¼µåœ–åƒæ¸¬è©¦
- æª¢æŸ¥é›™è¼¸å‡ºæ–‡ä»¶
- é©—è­‰å¾Œè™•ç†é‚è¼¯
- æ¸¬è©¦éŒ¯èª¤è™•ç†

**æ­¥é©Ÿ 7: æ‰¹é‡æ¸¬è©¦**

- ä½¿ç”¨ 10-20 å¼µåœ–åƒæ¸¬è©¦
- é©—è­‰å¤šç·šç¨‹ç©©å®šæ€§
- æª¢æŸ¥è¼¸å‡ºè³ªé‡

### Testing Strategy

**æ¸¬è©¦å±¤ç´š**:

1. **å–®å…ƒæ¸¬è©¦ï¼ˆæ‰‹å‹•ï¼‰**:
```python
# æ¸¬è©¦å…¬å¼æ¸…ç†
text = r'\[ E = mc^2 \quad(equation 1) \]'
result = clean_formula(text)
assert result == r'\[ E = mc^2 \]'

# æ¸¬è©¦ç‰¹æ®Šæ¨™è¨˜æå–
text = '<|ref|>test<|/ref|><|det|>bbox<|/det|>'
matches, matches_other = re_match(text)
assert len(matches_other) > 0
```

2. **é›†æˆæ¸¬è©¦**:
```bash
# æ¸¬è©¦å–®åœ–è™•ç†
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root test_images \
  --save_root test_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 1

# æª¢æŸ¥è¼¸å‡º
ls test_output/
cat test_output/test_det.md
cat test_output/test.md
```

3. **æ‰¹é‡æ¸¬è©¦**:
```bash
# æ¸¬è©¦å¤šç·šç¨‹
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root demo_data/omnidocbench_demo/images \
  --save_root result/deepseek_test \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 10
```

4. **éŒ¯èª¤å ´æ™¯æ¸¬è©¦**:
- ä¸å­˜åœ¨çš„åœ–åƒè·¯å¾‘
- éŒ¯èª¤çš„ API endpoint
- éŒ¯èª¤çš„ API key
- ç¶²çµ¡è¶…æ™‚

### Acceptance Criteria

**å¿…é ˆæ»¿è¶³çš„æ¨™æº–**:

1. âœ… **æ–‡ä»¶å‰µå»º**: `tools/model_infer/deepseek_ocr_inf.py` å­˜åœ¨ä¸”å¯åŸ·è¡Œ

2. âœ… **API èª¿ç”¨**: æˆåŠŸé€šé OpenAI Compatible API èª¿ç”¨ vllm
   - æ­£ç¢ºçš„ endpoint æ ¼å¼
   - æ­£ç¢ºçš„è«‹æ±‚çµæ§‹
   - æ­£ç¢ºè™•ç†éŸ¿æ‡‰

3. âœ… **é›™è¼¸å‡ºç”Ÿæˆ**:
   - æ¯å€‹åœ–åƒç”Ÿæˆ `{basename}_det.md`ï¼ˆåŸå§‹è¼¸å‡ºï¼‰
   - æ¯å€‹åœ–åƒç”Ÿæˆ `{basename}.md`ï¼ˆæ¸…ç†å¾Œè¼¸å‡ºï¼‰
   - å…©å€‹æ–‡ä»¶å…§å®¹ä¸åŒ

4. âœ… **å¾Œè™•ç†æ­£ç¢º**:
   - `clean_formula()` æ­£ç¢ºç§»é™¤ `\quad(...)` æ¨™è¨˜
   - `re_match()` æ­£ç¢ºæå–ç‰¹æ®Šæ¨™è¨˜
   - ç‰¹æ®Šæ¨™è¨˜è¢«å®Œå…¨ç§»é™¤
   - å¤šé¤˜æ›è¡Œè¢«æ¸…ç†

5. âœ… **ä¸¦è¡Œè™•ç†**:
   - å¤šç·šç¨‹æ­£å¸¸å·¥ä½œ
   - é¡¯ç¤º tqdm é€²åº¦æ¢
   - ç·šç¨‹æ•¸å¯é…ç½®

6. âœ… **éŒ¯èª¤è™•ç†**:
   - API å¤±æ•—æ™‚å„ªé›…è™•ç†ï¼ˆä¸å´©æ½°ï¼‰
   - åœ–åƒè®€å–å¤±æ•—æ™‚è·³é
   - é¡¯ç¤ºéŒ¯èª¤æ—¥èªŒ

7. âœ… **åƒæ•¸åŒ–é…ç½®**:
   - æ‰€æœ‰é—œéµåƒæ•¸å¯é€šéå‘½ä»¤è¡Œè¨­ç½®
   - æä¾› `--help` èªªæ˜
   - åƒæ•¸é©—è­‰ï¼ˆå¿…å¡«åƒæ•¸ï¼‰

8. âœ… **çµæœçµ±è¨ˆ**:
   - é¡¯ç¤ºç¸½åœ–åƒæ•¸
   - é¡¯ç¤ºæˆåŠŸ/å¤±æ•—æ•¸é‡
   - é¡¯ç¤ºè™•ç†æ™‚é–“ï¼ˆå¯é¸ï¼‰

**é©—è­‰æ–¹æ³•**:

```bash
# 1. é‹è¡Œè…³æœ¬
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root demo_data/omnidocbench_demo/images \
  --save_root result/deepseek_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --model_name deepseek-ai/DeepSeek-OCR \
  --threads 10

# 2. æª¢æŸ¥è¼¸å‡º
ls result/deepseek_output/ | wc -l  # æ‡‰è©²æ˜¯åœ–åƒæ•¸ * 2

# 3. é©—è­‰å…§å®¹
head result/deepseek_output/*_det.md  # æ‡‰åŒ…å«ç‰¹æ®Šæ¨™è¨˜
head result/deepseek_output/*.md      # ä¸æ‡‰åŒ…å«ç‰¹æ®Šæ¨™è¨˜

# 4. æª¢æŸ¥å…¬å¼æ¸…ç†
grep "\\quad" result/deepseek_output/*.md  # æ‡‰è©²æ²’æœ‰çµæœ
```

---

## Developer Resources

### File Paths Reference

**æ–°å»ºæ–‡ä»¶**:
```
tools/model_infer/deepseek_ocr_inf.py  # ä¸»æ¨ç†è…³æœ¬
```

**åƒè€ƒæ–‡ä»¶**:
```
tools/model_infer/gpt_4o_inf.py                    # OpenAI API èª¿ç”¨åƒè€ƒ
configs/run_dpsk_ocr_eval_batch.py                 # å¾Œè™•ç†é‚è¼¯åƒè€ƒ
configs/DeepSeek-OCR-vllm/config.py                # Prompt é…ç½®åƒè€ƒ
configs/DeepSeek-OCR-vllm/process/image_process.py # åœ–åƒé è™•ç†åƒè€ƒï¼ˆä¸ä½¿ç”¨ï¼‰
```

**æ¸¬è©¦æ•¸æ“š**:
```
demo_data/omnidocbench_demo/images/  # å®˜æ–¹æ¼”ç¤ºåœ–åƒ
```

**è¼¸å‡ºç›®éŒ„**:
```
result/deepseek_output/              # ç”¨æˆ¶æŒ‡å®šçš„è¼¸å‡ºç›®éŒ„
â”œâ”€â”€ page_001_det.md                  # åŸå§‹è¼¸å‡º
â”œâ”€â”€ page_001.md                      # æ¸…ç†å¾Œè¼¸å‡º
â”œâ”€â”€ page_002_det.md
â”œâ”€â”€ page_002.md
â””â”€â”€ ...
```

### Key Code Locations

**æ ¸å¿ƒå‡½æ•¸ä½ç½®**ï¼ˆåœ¨æ–°æ–‡ä»¶ä¸­ï¼‰:

```python
# tools/model_infer/deepseek_ocr_inf.py

PROMPT = '...'                                    # L13: Prompt å®šç¾©

def clean_formula(text: str) -> str:             # L20-35: å…¬å¼æ¸…ç†
    ...

def re_match(text: str) -> tuple:                # L37-48: ç‰¹æ®Šæ¨™è¨˜æå–
    ...

def get_deepseek_response(                       # L50-75: API èª¿ç”¨
    image_path: str,
    client: OpenAI,
    model_name: str
) -> str:
    ...

def process_image(args) -> str:                  # L77-115: å–®åœ–è™•ç†
    ...

def main():                                       # L117-160: ä¸»å‡½æ•¸
    ...
```

**åƒè€ƒä»£ç¢¼ä½ç½®**:

```python
# tools/model_infer/gpt_4o_inf.py
def get_gpt_response(image_path):                # L39-68: API èª¿ç”¨æ¨¡æ¿
def process_image(args):                          # L70-80: å–®åœ–è™•ç†æ¨¡æ¿
def main():                                       # L82-111: ä¸»å‡½æ•¸æ¨¡æ¿

# configs/run_dpsk_ocr_eval_batch.py
def clean_formula(text):                          # L53-68: å…¬å¼æ¸…ç†
def re_match(text):                               # L70-79: ç‰¹æ®Šæ¨™è¨˜æå–
# é›™è¼¸å‡ºé‚è¼¯                                       # L145-161
```

### Testing Locations

**æ¸¬è©¦æ–¹å¼**:
- ä½¿ç”¨å¯¦éš›æ•¸æ“šæ¸¬è©¦ï¼ˆç„¡å–®å…ƒæ¸¬è©¦æ¡†æ¶ï¼‰
- æ¸¬è©¦æ•¸æ“š: `demo_data/omnidocbench_demo/images/`
- æ¸¬è©¦è¼¸å‡º: ç”¨æˆ¶æŒ‡å®šçš„ `save_root` ç›®éŒ„

**æ¸¬è©¦å‘½ä»¤**:
```bash
# å¿«é€Ÿæ¸¬è©¦ï¼ˆ1 ç·šç¨‹ï¼‰
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root demo_data/omnidocbench_demo/images \
  --save_root test_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 1

# æ‰¹é‡æ¸¬è©¦ï¼ˆ10 ç·šç¨‹ï¼‰
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root demo_data/omnidocbench_demo/images \
  --save_root result/deepseek_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 10
```

### Documentation to Update

**éœ€è¦æ›´æ–°çš„æ–‡æª”**:

1. **README.md** - æ·»åŠ  deepseek_ocr_inf.py ä½¿ç”¨èªªæ˜:
```markdown
## DeepSeek-OCR æ¨ç†

é€šé OpenAI Compatible API èª¿ç”¨ vllm DeepSeek-OCR æœå‹™:

```bash
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root ./images \
  --save_root ./output \
  --api_key YOUR_API_KEY \
  --base_url http://vllm-server:8000/v1 \
  --model_name deepseek-ai/DeepSeek-OCR \
  --threads 10
```

2. **tools/model_infer/README.md**ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- æ·»åŠ è…³æœ¬èªªæ˜

3. **CHANGELOG.md**ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- è¨˜éŒ„æ–°åŠŸèƒ½:
```markdown
## [Unreleased]
### Added
- DeepSeek-OCR æ¨ç†è…³æœ¬ (tools/model_infer/deepseek_ocr_inf.py)
  - æ”¯æŒ OpenAI Compatible API èª¿ç”¨
  - é›™è¼¸å‡º: åŸå§‹ + æ¸…ç†å¾Œ Markdown
  - å¤šç·šç¨‹ä¸¦è¡Œè™•ç†
```

**ä¸éœ€è¦æ›´æ–°**:
- è©•ä¼°é…ç½®æ–‡ä»¶ï¼ˆconfigs/*.yamlï¼‰- æ¨ç†è…³æœ¬ä¸å½±éŸ¿è©•ä¼°
- é–‹ç™¼æŒ‡å—ï¼ˆdocs/development-guide.mdï¼‰- æ¨ç†è…³æœ¬æ˜¯å·¥å…·ï¼Œéæ ¸å¿ƒæ¶æ§‹
- æ¶æ§‹æ–‡æª”ï¼ˆdocs/architecture.mdï¼‰- æ¨ç†è…³æœ¬ä¸æ”¹è®Šæ¶æ§‹

---

## UX/UI Considerations

**ç„¡ UI/UX å½±éŸ¿** - é€™æ˜¯ç´”å‘½ä»¤è¡Œå·¥å…·ã€‚

**å‘½ä»¤è¡Œ UX è€ƒæ…®**:

1. **é€²åº¦åé¥‹**:
   - ä½¿ç”¨ tqdm é¡¯ç¤ºè™•ç†é€²åº¦æ¢
   - é¡¯ç¤ºç•¶å‰è™•ç†çš„æ–‡ä»¶å
   - é¡¯ç¤ºå‰©é¤˜æ™‚é–“ä¼°è¨ˆ

2. **éŒ¯èª¤ä¿¡æ¯**:
   - æ¸…æ™°çš„éŒ¯èª¤å‰ç¶´ `[ERROR]`
   - å…·é«”çš„éŒ¯èª¤åŸå› 
   - ä¸å½±éŸ¿å…¶ä»–æ–‡ä»¶è™•ç†

3. **æˆåŠŸåé¥‹**:
   - é¡¯ç¤ºè™•ç†çµ±è¨ˆï¼ˆç¸½æ•¸/æˆåŠŸ/å¤±æ•—ï¼‰
   - é¡¯ç¤ºè¼¸å‡ºç›®éŒ„ä½ç½®

4. **åƒæ•¸é©—è­‰**:
   - å¿…å¡«åƒæ•¸ç¼ºå¤±æ™‚é¡¯ç¤ºæ¸…æ™°æç¤º
   - æä¾› `--help` èªªæ˜

**ç¤ºä¾‹è¼¸å‡º**:
```
é–‹å§‹ä½¿ç”¨ 10 å€‹ç·šç¨‹è™•ç† 50 å¼µåœ–åƒ...
è™•ç†é€²åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:30<00:00,  1.67it/s]
è™•ç†å®Œæˆ: ç¸½å…± 50 å¼µåœ–åƒ, æˆåŠŸ 48 å¼µ, å¤±æ•— 2 å¼µ
çµæœä¿å­˜åˆ°: result/deepseek_output/
```

---

## Testing Approach

### æ¸¬è©¦æ¡†æ¶

**ç„¡æ­£å¼æ¸¬è©¦æ¡†æ¶** - ä½¿ç”¨æ‰‹å‹•é©—è­‰å’Œå¯¦éš›æ•¸æ“šæ¸¬è©¦

### æ¸¬è©¦ç­–ç•¥

**1. åŠŸèƒ½é©—è­‰æ¸¬è©¦**:

```bash
# æ¸¬è©¦ 1: API é€£é€šæ€§
curl $VLLM_BASE_URL/v1/models

# æ¸¬è©¦ 2: å–®åœ–è™•ç†
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root test_images \
  --save_root test_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 1

# é©—è­‰è¼¸å‡º
ls test_output/*_det.md  # åŸå§‹è¼¸å‡ºå­˜åœ¨
ls test_output/*.md      # æ¸…ç†å¾Œè¼¸å‡ºå­˜åœ¨
```

**2. å¾Œè™•ç†é‚è¼¯æ¸¬è©¦**:

```bash
# æª¢æŸ¥å…¬å¼æ¸…ç†
grep "\\quad" test_output/*.md  # æ‡‰è©²æ²’æœ‰çµæœ

# æª¢æŸ¥ç‰¹æ®Šæ¨™è¨˜ç§»é™¤
grep "<|ref|>" test_output/*.md  # æ‡‰è©²æ²’æœ‰çµæœ
grep "<|det|>" test_output/*.md  # æ‡‰è©²æ²’æœ‰çµæœ

# å°æ¯”åŸå§‹å’Œæ¸…ç†å¾Œçš„æ–‡ä»¶
diff test_output/test_det.md test_output/test.md  # æ‡‰è©²æœ‰å·®ç•°
```

**3. å¤šç·šç¨‹æ¸¬è©¦**:

```bash
# æ¸¬è©¦ä¸¦ç™¼è™•ç†
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root demo_data/omnidocbench_demo/images \
  --save_root result/deepseek_parallel_test \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 10

# é©—è­‰æ‰€æœ‰æ–‡ä»¶éƒ½è¢«è™•ç†
ls demo_data/omnidocbench_demo/images/ | wc -l
ls result/deepseek_parallel_test/*.md | wc -l  # æ‡‰è©²æ˜¯å‰è€…çš„ 2 å€
```

**4. éŒ¯èª¤è™•ç†æ¸¬è©¦**:

```bash
# æ¸¬è©¦éŒ¯èª¤çš„ API endpoint
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root test_images \
  --save_root test_output \
  --api_key $VLLM_API_KEY \
  --base_url http://invalid-url:8000/v1 \
  --threads 1
# æ‡‰è©²é¡¯ç¤ºéŒ¯èª¤ä½†ä¸å´©æ½°

# æ¸¬è©¦ä¸å­˜åœ¨çš„åœ–åƒç›®éŒ„
python tools/model_infer/deepseek_ocr_inf.py \
  --image_root non_existent_dir \
  --save_root test_output \
  --api_key $VLLM_API_KEY \
  --base_url $VLLM_BASE_URL \
  --threads 1
# æ‡‰è©²é¡¯ç¤ºéŒ¯èª¤ä½†ä¸å´©æ½°
```

### æ¸¬è©¦è¦†è“‹ç¯„åœ

**æ ¸å¿ƒåŠŸèƒ½è¦†è“‹**:
- âœ… API èª¿ç”¨ï¼ˆæ­£å¸¸/ç•°å¸¸ï¼‰
- âœ… åœ–åƒç·¨ç¢¼
- âœ… é›™è¼¸å‡ºç”Ÿæˆ
- âœ… å…¬å¼æ¸…ç†
- âœ… ç‰¹æ®Šæ¨™è¨˜ç§»é™¤
- âœ… å¤šç·šç¨‹è™•ç†
- âœ… é€²åº¦é¡¯ç¤º
- âœ… éŒ¯èª¤è™•ç†

**é‚Šç•Œæƒ…æ³è¦†è“‹**:
- âœ… ç©ºåœ–åƒç›®éŒ„
- âœ… ä¸æ”¯æŒçš„åœ–åƒæ ¼å¼
- âœ… API è¶…æ™‚
- âœ… ç¶²çµ¡éŒ¯èª¤
- âœ… æ–‡ä»¶å¯«å…¥æ¬Šé™å•é¡Œ

### é©—è­‰æ¸…å–®

å®Œæˆå¯¦ä½œå¾Œæª¢æŸ¥:

- [ ] æ–‡ä»¶å·²å‰µå»º: `tools/model_infer/deepseek_ocr_inf.py`
- [ ] API èª¿ç”¨æˆåŠŸ
- [ ] é›™è¼¸å‡ºæ–‡ä»¶éƒ½ç”Ÿæˆ
- [ ] `_det.md` åŒ…å«åŸå§‹è¼¸å‡º
- [ ] `.md` ä¸åŒ…å«ç‰¹æ®Šæ¨™è¨˜
- [ ] å…¬å¼æ¸…ç†æ­£ç¢º
- [ ] å¤šç·šç¨‹æ­£å¸¸å·¥ä½œ
- [ ] é€²åº¦æ¢æ­£å¸¸é¡¯ç¤º
- [ ] éŒ¯èª¤å„ªé›…è™•ç†
- [ ] çµ±è¨ˆä¿¡æ¯æ­£ç¢ºé¡¯ç¤º
- [ ] å‘½ä»¤è¡Œåƒæ•¸æ­£å¸¸å·¥ä½œ
- [ ] `--help` é¡¯ç¤ºæ­£ç¢º

---

## Deployment Strategy

### Deployment Steps

**é€™æ˜¯æ–°å¢æ–‡ä»¶ï¼Œéƒ¨ç½²éå¸¸ç°¡å–®**:

1. âœ… **æäº¤ä»£ç¢¼**:
```bash
git add tools/model_infer/deepseek_ocr_inf.py
git commit -m "feat(infer): add DeepSeek-OCR inference script with OpenAI API

- Add deepseek_ocr_inf.py for remote vllm API calls
- Support dual output: raw (_det.md) and cleaned (.md)
- Integrate clean_formula() and re_match() post-processing
- Support multi-threaded parallel processing
- Configurable via CLI arguments (api_key, base_url, model_name, threads)

Refs: gpt_4o_inf.py, run_dpsk_ocr_eval_batch.py"
```

2. âœ… **æ›´æ–° requirements.txt**ï¼ˆå¦‚æœ openai ä¸åœ¨åˆ—è¡¨ä¸­ï¼‰:
```bash
# æª¢æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ 
pip freeze | grep openai

# å¦‚æœæ²’æœ‰ï¼Œæ·»åŠ åˆ° requirements.txt
echo "openai>=1.0.0" >> requirements.txt
git add requirements.txt
git commit -m "chore: add openai dependency for API inference"
```

3. âœ… **æ›´æ–°æ–‡æª”**:
```bash
# æ›´æ–° README.md æ·»åŠ ä½¿ç”¨èªªæ˜
git add README.md
git commit -m "docs: add DeepSeek-OCR inference script usage"
```

4. âœ… **æ¨é€åˆ°é ç¨‹**:
```bash
git push origin main  # æˆ–æ‚¨çš„åˆ†æ”¯å
```

5. âœ… **é€šçŸ¥ç”¨æˆ¶**:
- æä¾›ä½¿ç”¨ç¤ºä¾‹
- èªªæ˜ vllm æœå‹™é…ç½®è¦æ±‚

### Rollback Plan

**å›æ»¾éå¸¸ç°¡å–®ï¼ˆæ–°æ–‡ä»¶ä¸å½±éŸ¿ç¾æœ‰åŠŸèƒ½ï¼‰**:

```bash
# æ–¹æ¡ˆ 1: åˆªé™¤æ–‡ä»¶
git rm tools/model_infer/deepseek_ocr_inf.py
git commit -m "revert: remove deepseek_ocr_inf.py"
git push

# æ–¹æ¡ˆ 2: å›é€€ commit
git revert <commit-hash>
git push

# æ–¹æ¡ˆ 3: ç›´æ¥åˆªé™¤æ–‡ä»¶ï¼ˆå¦‚æœæœªæäº¤ï¼‰
rm tools/model_infer/deepseek_ocr_inf.py
```

**å½±éŸ¿ç¯„åœ**: ç„¡ - é€™æ˜¯ç¨ç«‹çš„æ–°æ–‡ä»¶ï¼Œä¸å½±éŸ¿:
- ç¾æœ‰æ¨ç†è…³æœ¬
- è©•ä¼°ä»»å‹™
- æ ¸å¿ƒæ¶æ§‹
- å…¶ä»–æ¨¡å¡Š

### Monitoring

**é‹è¡Œæ™‚ç›£æ§**:

1. **é€²åº¦ç›£æ§**:
   - tqdm é€²åº¦æ¢é¡¯ç¤ºå¯¦æ™‚é€²åº¦
   - ä¼°è¨ˆå‰©é¤˜æ™‚é–“

2. **æˆåŠŸç‡ç›£æ§**:
   - é¡¯ç¤ºæˆåŠŸ/å¤±æ•—çµ±è¨ˆ
   - è­˜åˆ¥å•é¡Œæ–‡ä»¶

3. **éŒ¯èª¤æ—¥èªŒ**:
   - `[ERROR]` å‰ç¶´çš„éŒ¯èª¤ä¿¡æ¯
   - å…·é«”çš„å¤±æ•—åŸå› 

4. **æ€§èƒ½ç›£æ§**:
   - è™•ç†é€Ÿåº¦ï¼ˆimages/secï¼‰
   - API éŸ¿æ‡‰æ™‚é–“

**ç¤ºä¾‹ç›£æ§è¼¸å‡º**:
```
é–‹å§‹ä½¿ç”¨ 10 å€‹ç·šç¨‹è™•ç† 50 å¼µåœ–åƒ...
è™•ç†é€²åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:30<00:00,  1.67it/s]
[ERROR] è™•ç†å¤±æ•— page_010.jpg: Connection timeout
[ERROR] è™•ç†å¤±æ•— page_025.jpg: Invalid image format
è™•ç†å®Œæˆ: ç¸½å…± 50 å¼µåœ–åƒ, æˆåŠŸ 48 å¼µ, å¤±æ•— 2 å¼µ
å¹³å‡é€Ÿåº¦: 1.67 images/sec
çµæœä¿å­˜åˆ°: result/deepseek_output/
```

**æ—¥èªŒå»ºè­°**ï¼ˆå¯é¸å¢å¼·ï¼‰:
```python
# å¯é¸: æ·»åŠ è©³ç´°æ—¥èªŒåˆ°æ–‡ä»¶
import logging
logging.basicConfig(
    filename='deepseek_infer.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
```

---

## ğŸ“ ç¸½çµ

é€™æ˜¯ä¸€å€‹ **Level 0** å°ˆæ¡ˆï¼ˆå–®ä¸€åŸå­è®Šæ›´ï¼‰ï¼Œæ–°å¢ä¸€å€‹ç¨ç«‹çš„æ¨ç†è…³æœ¬:

**è®Šæ›´ç¯„åœ**: æ–°å»º `tools/model_infer/deepseek_ocr_inf.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- âœ… OpenAI Compatible API èª¿ç”¨ vllm
- âœ… DeepSeek-OCR å°ˆç”¨å¾Œè™•ç†
- âœ… é›™è¼¸å‡ºï¼ˆåŸå§‹ + æ¸…ç†ï¼‰
- âœ… å¤šç·šç¨‹ä¸¦è¡Œè™•ç†

**æŠ€è¡“æ±ºç­–**:
- åƒè€ƒ `gpt_4o_inf.py` æ¶æ§‹ï¼ˆOpenAI SDK + å¤šç·šç¨‹ï¼‰
- ç§»æ¤ `run_dpsk_ocr_eval_batch.py` å¾Œè™•ç†é‚è¼¯
- åœ–åƒé è™•ç†ç”± vllm æœå‹™ç«¯è™•ç†ï¼ˆå·²é…ç½®ï¼‰

**å¯¦ä½œæº–å‚™**:
- âœ… ä¸Šä¸‹æ–‡å·²å……åˆ†æ”¶é›†
- âœ… åƒè€ƒä»£ç¢¼å·²è­˜åˆ¥
- âœ… æŠ€è¡“æ–¹æ¡ˆå·²æ˜ç¢º
- âœ… æ¸¬è©¦ç­–ç•¥å·²è¦åŠƒ

**ä¸‹ä¸€æ­¥**: é–‹å§‹å¯¦ä½œè…³æœ¬ä¸¦æ¸¬è©¦é©—è­‰ã€‚
